--- 
title_meta  : Chapter 2
title       : Data the Tidy Way
description : "In this chapter, you will learn some of the fundamentals of taking raw data and cleaning it to form tidy data, the fundamental currency of data science and visualization tools such as ggplot2."

--- type:NormalExercise xp:100 skills:1 key:3db54e3447
## Intro to Data Science and Some (Un)Tidy Data

Now that you've been introduced to the fundamentals of programming in R, the next step is to learning how to data science in R. Here, we'll present some of the concepts we wish we would have learned when we first started, and go through some example data on the way. (1, see hint)

By the end of this chapter, you should be familiar with:

- understanding how and why R is useful for data science
- explain the advantages and concepts of tidy data
- familiarity with modern R conventions that make it a powerful tool for data science

On to our first concept: **tidy data**

Many times when we run into data from the wild, it is often a jumble of messy character strings, confounding variables, missing data, and worse. The process of converting a *raw data* to *tidy data* goes by many names - here we will refer to it as *data munging* or *cleaning*. The goal of this process is singular:

> **"A dataset is a collection of *values*, organized in two ways: every value belongs to a *variable* and *observation*.**
> **A *variable* contains all *values* that measure the same underlying attribute across units.**
> **An *observation* contains all *values* measured on the same unit across attributes.**

To emphasize this concept, take a look at the sample code on the right showing untidy data (presented in two different ways), and print the `untidy_df` and `untidy_df_2` object out (hint: Ctrl/Cmd+Enter to run a line!). How does this dataset run counter to the principle stated above? 


*** =instructions
- Take a moment to ponder how you might reorganize this data, then simply click submit to move forward!


*** =hint
(1) These concepts introduced here lean heavily on the formal treatise by Hadley Wickham, the lead developer of many of the packages we will be using throughout this course. See the [tidy data paper](http://vita.had.co.nz/papers/tidy-data.html) and the accompanying [R code heavy version](https://cran.r-project.org/web/packages/tidyr/vignettes/tidy-data.html). Definitely take the time to checkout these resources!


*** =pre_exercise_code
```{r}
# run this without showing user
x <- 5
```

*** =sample_code
```{r}
# Untidy data example
untidy_df <- data.frame(name = c("John Smith", "Jane Doe", "Mary Johnson"),
                        treatmenta = c(NA, 4, 6),
                        treatmentb = c(18, 1, 7))
untidy_df

# Untidy data example 2
untidy_df_2 <- data.frame(treatment = c("a", "b"),
                          John.Smith = c(NA, 18),
                          Jane.Doe = c(4, 1),
                          Mary.Johnson = c(6, 7))
untidy_df_2
```

*** =solution
```{r}

```

*** =sct
```{r}
test_error()
test_object("x",
            undefined_msg = "Make sure to define `x`!",
            incorrect_msg = "Have you correctly assigned 5 to `x`!")
success_msg("Good job! Head over to the next exercise!")

```



--- type:NormalExercise lang:r xp: skills: key:489128dafe
## A Tidy Sample

So we just saw what some untidy looks like, with all of its variable and values mixed up. If you took a moment to ponder the format of the previous data (to remind yourself, run the line `untidy_df` and see the output in the console), you took stock of the following.

- There exist three different people with different *names*, who underwent different *treatments*, `treatmenta` and/or `treatmentb`, which resulted in different *values* in each case (with no treatment application (e.g. missing data) represented as `NA`)

Given this, we can come up with three *variables* describing each unique *observation* (application of treatment X to person Y with readout/value Z):

- name
- treatment
- value

Hence, we can rewrite our untidy data into a tidy format! See the sample code for the solution. 

With this in mind, let's move on to a real world dataset 'from the wild'!

*** =instructions
Check out the tidy transformation of our untidy data, and get ready to start coding!

*** =hint
"It is often said that 80% of data analysis is spent on the process of cleaning and preparing
the data (Dasu and Johnson 2003)" - if you haven't already, check out [this paper on tidy data](http://vita.had.co.nz/papers/tidy-data.pdf) for extra credit!

*** =pre_exercise_code
```{r}
# Untidy data example
untidy_df <- data.frame(name = c("John Smith", "Jane Doe", "Mary Johnson"),
                        treatmenta = c(NA, 4, 6),
                        treatmentb = c(18, 1, 7))

```

*** =sample_code
```{r}
untidy_df # run me to see the untidy version

# Note: you cannot run this code line by line
# Instead, select the entire region and then Cmd/Ctrl+Enter and run
tidy_df <- data.frame(name = rep(c("Jane Doe", "John Smith", "Mary Johnson"), each = 2),
                      treatment = rep(c("a", "b"), 3),
                      value = c(4, 1, NA, 18, 6, 7))
tidy_df

```

*** =solution
```{r}

```

*** =sct
```{r}
test_error()
test_object("untidy_df",
            undefined_msg = "Make sure to define `x`!",
            incorrect_msg = "Have you correctly assigned 5 to `x`!")
success_msg("Good job! Head over to the next exercise!")

```




--- type:NormalExercise lang:r xp: skills: key:75bda68f14
## Real (Messy) Data: Income Distribution by Religion

Time for you to take a look at some actual, raw data. Here we have a survey done by Pew Research that examines the relationship between income and religious affiliation. We've already loaded the dataset up for you in the background under `pew`, but if you want to explore it on your own computer, [here is the data](http://stat405.had.co.nz/data/pew.txt).

Recalling chapter 1, check out the dataset on your own, and let's apply our tidy thinking to figure out what we need to change.



*** =instructions
- What do the first and last rows of the data look like?
- What are the dimensions? 
- What does a simple (naive) summary of the data give us? 
- What is the structure of the data?

*** =hint
Use the functions you learned from chapter 1 - namely, `head()`, `tail()`, `dim()`, `summary()`, and `str()` to preview the dataset on hand.

*** =pre_exercise_code
```{r}
load(url("http://s3.amazonaws.com/assets.datacamp.com/production/course_1886/datasets/pew.RData"))

```

*** =sample_code
```{r}
## Your code here
pew

```

*** =solution
```{r}

```

*** =sct
```{r}
test_error()
test_object("pew",
            undefined_msg = "Make sure to define `x`!",
            incorrect_msg = "Have you correctly assigned 5 to `x`!")
success_msg("Good job! Head over to the next exercise!")

```

--- type:NormalExercise lang:r xp: skills: key:426a68171c
## Refactoring Columns Into a Variable

You might have noticed that the columns contain a variety of income *levels* (e.g. *values*)..so you might consider *income* to be a *variable* in its own right. Furthermore, an individual observation will be a combination of a religion crossed with a specific income level.

Before we go on, first, I highly recommend checking out the [Data Wrangling with dplyr and tidyr Cheat Sheet](https://www.rstudio.com/wp-content/uploads/2015/02/data-wrangling-cheatsheet.pdf) by RStudio, as this will be an invaluable resource throughout this course (and in your work).

Back to our data..what we want to do is *gather* our columns into a single variable - income. To accomplish this, let's use the `tidyr` package. A quick example with the built-in `iris` dataset is shown in the Sample Code.


*** =instructions
Similar to the `iris` dataset in the sample code, refactor the `pew` dataset such that the data is tidy, with variables `religion`, `income`, and `value` into an object called `pew_df`.

*** =hint
See the sample code and your data wrangling cheat sheet for an example of how to use `tidyr::gather()`. Note that the opposite of this is `tidyr::spread()`.

*** =pre_exercise_code
```{r}
load(url("http://s3.amazonaws.com/assets.datacamp.com/production/course_1886/datasets/pew.RData"))
library(tidyr)

```

*** =sample_code
```{r}
# Example of gathering variables with the iris dataset
# Here, we specify new variables: 
# - a *key* column, "measurement" (Sepal.Length, Petal.Width, etc.)
# - a *value* column, which are the values we measured
# - the *columns* (1:4) where values are in the original data.frame
iris_df <- tidyr::gather(iris, measurement, value, 1:4)
iris_df[1:3, ]


```

*** =solution
```{r}
pew_df <- tidyr::gather(pew, income, value, 2:ncol(pew))

```

*** =sct
```{r}
test_error()
test_object("pew_df",
            undefined_msg = "Make sure to define `pew_df`!",
            incorrect_msg = "Have you munged `pew`?")
success_msg("Good job! Head over to the next exercise!")

```

--- type:NormalExercise lang:r xp: skills: key:31d35975ad
## Gluing Sliced and Diced Data Together

Many times, we will encounter datasets that exist in multiple tables. While in this format we may be able to achieve a minimal representation of the data with less duplicated columns, we also make it much more difficult to actually work with the data!

Luckily for us, the package `dplyr` has a family of *join* functions that make the task of gluing data back together easier than ever. A swiss army knife of joins are available for your use - see your [cheat sheet](https://www.rstudio.com/wp-content/uploads/2015/02/data-wrangling-cheatsheet.pdf) or the sample code at right to see these joins in action!

In your R environment, we have available two tables describing gene expression data. 

- `ref` - annotation mappings between ENSEMBL gene identifiers and gene symbols for an assortment of 3000 genes
- `fpm` - fragments per million (aka expression strength) of 1000 genes pulled at random from a genome-wide assay

You'll be using these two objects over the next few exercises, so get cozy with them! You might want to explore them before working with them. 

Now, on with the task at hand: annotation through joins!

*** =instructions
- Combine `fpm` and `ref` into a new `fpm_anno`, such that genes whose expression was measured are annotated with gene symbol in addition to their ENSEMBL identifiers. 
- Only annotate genes whose expression was measured (e.g., you should not be seeing `NA` values in your final result).

*** =hint
A `key` value is a column which is present in both tables: what column looks very similar between the two (despite the different column names)? See the documentation for `dplyr::inner_join()` for exact usage and the sample code too.


*** =pre_exercise_code
```{r}
library(tidyr)
library(dplyr)

load(url("http://s3.amazonaws.com/assets.datacamp.com/production/course_1886/datasets/ref.RData"))
load(url("http://s3.amazonaws.com/assets.datacamp.com/production/course_1886/datasets/fpm.RData"))

```

*** =sample_code
```{r}
## Example of using dplyr::left_join()
dat1 <- data.frame(id = c("a", "b", "d"), reads = c(1, 2, 4))
dat2 <- data.frame(id = c("b", "e", "f"), counts = c(3, 9, 10))
dat3 <- data.frame(ALPHABET = c("d", "y", "z"), times = c(7, 7, 7))

## Check out each join's output
dplyr::left_join(dat1, dat2, by = "id")   
dplyr::right_join(dat1, dat2, by = "id")  
dplyr::full_join(dat1, dat2, by = "id")   
dplyr::inner_join(dat1, dat2, by = "id")  
dplyr::anti_join(dat1, dat2, by = "id")

## What to do if key columns don't have matching names:
dplyr::full_join(dat1, dat3, by = c("id" = "ALPHABET"))

## -------------------------------------
## Your task
## Create an object `fpm_anno` with the column SYMBOL from `ref` added to `fpm`
## Only output rows in `fpm` - do not include rows in `ref` without cell values
## BONUS: have SYMBOL and GENEID columns renamed to "symbol" and "ensembl_id"
##   (see dplyr::rename)

fpm      # expression data
ref      # annotation data

fpm_anno # your code result is this object: annotated expression data

```

*** =solution
```{r}
fpm_anno <- dplyr::right_join(ref, fpm,  by = c("GENEID" = "ensembl_id")) %>%
    dplyr::rename(ensembl_id = GENEID, symbol = SYMBOL)

```

*** =sct
```{r}
test_error()
test_object("fpm_anno",
            undefined_msg = "Make sure to define `fpm_anno`!",
            incorrect_msg = "Have you munged `ref` and `fpm`?")
success_msg("Good job! Head over to the next exercise!")

```



--- type:NormalExercise lang:r xp: skills: key:1b84416821
## Summarising Data I

Looking at our dataset, you might notice that we have multiple replicates from a given condition when we inspect the column names (see `colnames()`). For example, you'll see:

- `cell_a_1`
- `cell_a_2`
- ...

To assist us in visualization, one thing we might want to do is take the average value of expression across all replicates for a given condition with respect to a given gene. In other words, we want to *summarise* our data.

You might be able to imagine a way of taking the average across a given group of columns, and in base R parlance, doing something like the following on a dataset for columns 1 through 3 to find the average over the 1st index (rows):

`apply(dat[, 1:3], 1, mean)`

However, this doesn't scale well, and we would have to somehow repeat it for all our groups! Luckily, there's a better way with `dplyr`.


   

*** =instructions
First, let's use `tidyr::gather()` to convert our dataset from wide to long format, such that the columns are:

`ensembl_id`, `symbol`, `sample`, `value`

    
*** =hint
Make sure to specify the value columns correctly - in this case, exclude our annotation columns `symbol` and `ensembl_id`. Make a new object called `fpm_long` 
    

*** =pre_exercise_code
```{r}
library(dplyr)
library(tidyr)
load(url("http://s3.amazonaws.com/assets.datacamp.com/production/course_1886/datasets/fpm_anno.RData"))

```

*** =sample_code
```{r}
## Continue on with the `fpm_anno` object we created earlier
fpm_anno

## Use tidyr::gather() to organize data into the columns:
## `ensembl_id`, `symbol`, `sample`, `value`
fpm_long 
    

```

*** =solution
```{r}

fpm_long <- tidyr::gather(fpm_anno, sample, value, 3:ncol(fpm_anno))

```
	

*** =sct
```{r}
test_error()
test_object("fpm_long",
            undefined_msg = "Make sure to define `fpm_anno`!",
            incorrect_msg = "Have you munged `ref` and `fpm`?")
success_msg("Good job! Head over to the next exercise!")

```

--- type:NormalExercise lang:r xp: skills: key:6b6704a03c
## Summarising Data II

The structure we now have contains the columns `ensembl_id`, `symbol` (our two annotation columns), and `sample` (with values such as `cell_a_1`) and `value` (the expression strength).

You might notice however that the `sample` column actually contains two *separate* pieces of information - the cell type (`a` vs. `b`) and the replicate (`1` or `2`). In order to summarise our expression values, we need to split apart these two pieces of information first.

To accomplish this, we will use the function `tidyr::separate()` to split upon a delimiter, in this case the underscore (`_`), keeping only the cell type and replicate information (since we will also extract `cell` if we split on the underscore).

Lastly, we can drop this `cell` column, which is irrelevant since it provides no discriminatory information, using the `dplyr::select()` function. Note that one can select by specifying columns (`dplyr::select(dat, some_column_name)`) but also can *remove* columns by negation (`dplyr::select(dat, -column_to_drop)`). 

*** =instructions
Use `tidyr::separate()` to split the `sample` column into three new columns - `cell` (which should only contain the value `cell`), `cell_type` (`a` or `b`), and `replicate` (`1` or `2`). In addition, drop the irrelevant `cell` column using the `dplyr::select()` function using negation. Save this data into a new object called `fpm_sep`.
    
*** =hint
The documentation for `tidyr::separate()` is the data, the column to separate, into is the names of the new columns, and the last argument you need is sep, which is the delimiter (in this case an underscore, `"_"`). Don't forget to drop the `cell` column afterwards!

*** =pre_exercise_code
    ```{r}
library(dplyr)
library(tidyr)
load(url("http://s3.amazonaws.com/assets.datacamp.com/production/course_1886/datasets/fpm_long.RData"))

```

*** =sample_code
```{r}
## Continuing on with the `fpm_long` object we created prior
fpm_long

## Create a new data frame called `fpm_sep`
fpm_sep

```

*** =solution
```{r}
fpm_sep <- tidyr::separate(fpm_long, sample, c("cell", "cell_type", "replicate")) %>%
    dplyr::select(-cell)
    

```

*** =sct
```{r}
test_error()
test_object("fpm_sep",
            undefined_msg = "Make sure to define `fpm_sep`!",
            incorrect_msg = "Have you munged `fpm_anno`?")
success_msg("Good job! Head over to the next exercise!")

```

--- type:NormalExercise lang:r xp: skills: key:17efa72568
## Summarising Data III

Finally, we have a dataset that we can summarise the mean expression across different the replicates for a given cell type on a gene-level basis.

To accomplish this last step, we will make use of two functions. Firstly, we need to *group* our data on the basis of the genes (`ensembl_id`, `symbol`) and `cell_type`. We can do this using the `dplyr::group_by()` function. The result of this is that any *summary* operations will be performed *based on the group*, rather than simply per row. We can write this roughly as:

`dplyr::group_by(dat, grouping_variable_1, grouping_variable_2, ...)`
   
The second function provides the final outcome - `dplyr::summarise()`. Here, we provide the new column name and the operation by which to summarise across the rows. We could for example calculate the variance in expression by writing:

`dplyr::summarise(dat, variance_per_group = var(value))`


*** =instructions
Using the `dplyr::group_by()` and `dplyr::summarise()` functions, calculate the mean expression per gene and cell type. Save the object as `fpm_summary`, where the mean of the expression is saved into a column named `avg`.
      
*** =hint
Did you know you can link operations using the pipe (`%>%`) operator? Instead of saving each step as a separate function, simply use a pipe to link the operations together. This pipe essentially sends the output of one command as the input of another, e.g.:

`dat %>% dplyr::group_by(...) %>% dplyr::summarise(...)`

*** =pre_exercise_code
```{r}
load(url("http://s3.amazonaws.com/assets.datacamp.com/production/course_1886/datasets/fpm_sep.RData"))

```

*** =sample_code
```{r}
## Continuing on with our `fpm_sep` object from previously..
fpm_sep

## Save your grouped/summarised data into a new object, `fpm_summary`
fpm_summary

```

*** =solution
```{r}
fpm_summary <- dplyr::group_by(fpm_sep, ensembl_id, symbol, cell_type) %>%
    dplyr::summarise(avg = mean(value, na.rm = TRUE))

```

*** =sct
```{r}
test_error()
test_object("fpm_summary",
            undefined_msg = "Make sure to munge `fpm_sep`!",
            incorrect_msg = "Have you munged `fpm_sep`?")
success_msg("Good job! Head over to the next exercise!")

```

--- type:NormalExercise lang:r xp: skills: key:53c0281c34
## Summarising Data IV: Conclusion

Congrats! You've now stepped through using some of the fundamental operations in tidying and summarising a dataset. Of course, there's many more tools we haven't covered in the `dplyr` and `tidyr` packages, but we hope that you'll now be equipped to tackle new datasets with these diverse toolkits.

To conclude, let's look at the entire pipeline we have created - it may seem like we did a lot, but in reality, it actually is very few lines of code to go from raw to tidy to summarised! See the sample code at right for what you've built, and when you're ready, hit submit!

*** =instructions
Be amazed by how easy it is to munge, tidy, and analyze data using `dplyr` and `tidyr`.

*** =hint
Simply hit submit when you're ready!
    
*** =pre_exercise_code
```{r}
library(tidyr)
library(dplyr)

load(url("http://s3.amazonaws.com/assets.datacamp.com/production/course_1886/datasets/ref.RData"))
load(url("http://s3.amazonaws.com/assets.datacamp.com/production/course_1886/datasets/fpm.RData"))

```

*** =sample_code
```{r}
## The whole pipeline starting from `fpm` and `ref` objects
## We end on the tidied up dataset
## Explore each step by separating the individual lines into
## new objects and you'll see we recreated each step we took
df <- dplyr::right_join(ref, fpm,  by = c("GENEID" = "ensembl_id")) %>%
    dplyr::rename(ensembl_id = GENEID, symbol = SYMBOL) %>%
    tidyr::gather(sample, value, 3:ncol(fpm_anno)) %>%
    tidyr::separate(sample, c("cell", "cell_type", "replicate")) %>%
    dplyr::select(-cell)

## We use the tidied up dataset `df` to summarise
dfs <- dplyr::group_by(df, ensembl_id, symbol, cell_type) %>%
    dplyr::summarise(avg = mean(value, na.rm = TRUE))

```

*** =solution
```{r}

```

*** =sct
```{r}
test_error()
test_object("dfs",
            undefined_msg = "Make sure to munge `df`!",
            incorrect_msg = "Have you munged `df`?")
success_msg("Good job! Head over to the next exercise!")

```
